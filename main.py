import streamlit as st
import pandas as pd
import json
import re
import asyncio
from typing import Annotated, TypedDict
from sqlalchemy import create_engine, text

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages

# jobkorea_cli ëª¨ë“ˆ (ì™¸ë¶€ ì˜ì¡´)
from jobkorea_cli.models import Spec
from jobkorea_cli.llm import parse_spec, ask_required_batch, map_filters
from jobkorea_cli.cli import crawl_by_roles_multi

# -------- ëª¨ë¸ ë° DB ì—°ê²° -----------
model = ChatOpenAI(model="gpt-5-2025-08-07")
DB_CONNECTION_URL = 'postgresql+psycopg2://play:123@192.168.0.8:5432/team2'
engine = create_engine(DB_CONNECTION_URL)

# -------- ìƒíƒœ íƒ€ì… ë° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ -----------
class State(TypedDict):
    messages: Annotated[list, add_messages]

base_generate_prompt_ko = SystemMessage(
    "ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
    "ì…ë ¥ëœ ì§€ì› ì§ë¬´ì™€ ë³¸ì¸ ìŠ¤í™, ê²½ë ¥, ê²½í—˜ ë“±ì„ í† ëŒ€ë¡œ ìµœê³ ì˜ ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
)

base_generate_prompt_en = SystemMessage(
    "You are an assistant specialized in writing cover letters. "
    "Based on the given job position, personal qualifications, and experiences, write the best English cover letter."
)

reflection_prompt_ko = SystemMessage(
    "ë‹¹ì‹ ì€ ì¸ì‚¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤. "
    "ë°©ê¸ˆ ìƒì„±ëœ ìê¸°ì†Œê°œì„œë¥¼ ì½ê³  ë‚´ìš©, êµ¬ì²´ì„±, ì„¤ë“ë ¥, ì–´íˆ¬ ë“±ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ìƒì„¸í•˜ê²Œ í”¼ë“œë°±í•˜ì„¸ìš”."
)

reflection_prompt_en = SystemMessage(
    "You are a hiring manager. "
    "Please review the cover letter and provide detailed feedback on content, concreteness, persuasiveness, and tone."
)

def get_prompts(language: str):
    if language == 'en':
        return base_generate_prompt_en, reflection_prompt_en
    else:
        return base_generate_prompt_ko, reflection_prompt_ko

def make_job_prompt(base_prompt, company_culture=None, example_resume=None, char_limit=0):
    parts = [base_prompt.content]
    if company_culture:
        parts.append(f"\ní•´ë‹¹ íšŒì‚¬ì˜ ì¸ì¬ìƒ:\n{company_culture}")
    if example_resume:
        parts.append("\në‚´ë¶€ DB ìì†Œì„œ ì˜ˆì‹œ ì°¸ê³  ë‚´ìš©:")
        if isinstance(example_resume, dict):
            if example_resume.get("q"):
                parts.append(f"ìì†Œì„œ ë¬¸í•­:\n{example_resume['q']}")
            if example_resume.get("a"):
                parts.append(f"ì˜ˆì‹œ ë‹µë³€:\n{example_resume['a']}")
            if example_resume.get("advice"):
                parts.append(f"ì¶”ê°€ ì¡°ì–¸:\n{example_resume['advice']}")
        else:
            parts.append(str(example_resume))
    if char_limit > 0:
        parts.append(f"\nìê¸°ì†Œê°œì„œëŠ” ê¸€ì ìˆ˜ ìµœëŒ€ {char_limit}ìì´ë©°, ê°€ëŠ¥í•œ í•œ {int(char_limit * 0.9)}ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.")
    parts.append("\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.")
    return SystemMessage('\n'.join(parts))

def generate(state: State, generate_prompt: SystemMessage, char_limit: int = 0) -> State:
    for _ in range(3):
        answer = model.invoke([generate_prompt] + state["messages"])
        content = answer.content
        if char_limit <= 0 or len(content) >= char_limit * 0.9:
            return {"messages": [answer]}
    return {"messages": [answer]}

def reflect(state: State, reflection_prompt: SystemMessage) -> State:
    answer = model.invoke([reflection_prompt] + state["messages"])
    return {"messages": [HumanMessage(content=answer.content)]}

def pretty_print(text: str) -> str:
    sentences = re.split(r'(?<=[\.ã€‚!ï¼\?ï¼Ÿ])\s+', text.strip())
    return "\n\n".join(sentences)

def load_ideal_from_db(company, language):
    try:
        df = pd.read_sql("SELECT íšŒì‚¬, ì¸ì¬ìƒ_í‚¤ì›Œë“œ, ìš”ì•½, language FROM ideal_table", engine)
        filtered = df[(df['íšŒì‚¬'].astype(str).str.contains(company, case=False, na=False)) & (df['language'] == language)]
        if not filtered.empty:
            return filtered.iloc[0]['ì¸ì¬ìƒ_í‚¤ì›Œë“œ'], filtered.iloc[0]['ìš”ì•½']
    except Exception:
        pass
    return None, None

def load_resume_from_db(company, job):
    try:
        df = pd.read_sql("SELECT company, position, q, a, advice FROM merged_resume", engine)
        filtered = df[(df['company'].str.strip() == company) & (df['position'].str.contains(job, case=False, na=False))]
        return filtered
    except Exception:
        return pd.DataFrame()

def company_ideal_talent_api(model: ChatOpenAI, company_name: str, lang: str = 'ko') -> dict:
    if lang == 'ko':
        query = (f"'{company_name}' íšŒì‚¬ì˜ ì¸ì¬ìƒê³¼ í•µì‹¬ ê°€ì¹˜Â·ë¬¸í™”ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì„¸ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”. "
                 "ì¶œë ¥ ì˜ˆì‹œ: "
                 "{\"íšŒì‚¬ëª…\": \"ì‚¼ì„±ì „ì\", \"ì¸ì¬ìƒ_í‚¤ì›Œë“œ\": [\"ë„ì „\", \"ì°½ì˜\", \"í˜‘ë ¥\"], \"ìš”ì•½\": \"í˜ì‹ ì„ ì£¼ë„í•˜ëŠ” ì¸ì¬\"}")
    elif lang == 'en':
        query = (f"Please summarize the ideal talent and core values of '{company_name}' company in JSON format with three items. "
                 "Example format: "
                 "{\"CompanyName\": \"Samsung Electronics\", \"KeyQualities\": [\"Challenge\", \"Creativity\", \"Collaboration\"], \"Summary\": \"Talent leading innovation\"}")
    else:
        query = f"Please provide the ideal talent description of '{company_name}' in {lang} in JSON format."
    response = model.invoke([HumanMessage(content=query)]).content
    try:
        return json.loads(response)
    except json.JSONDecodeError:
        return {
            "íšŒì‚¬ëª…" if lang == 'ko' else "CompanyName": company_name,
            "ì¸ì¬ìƒ_í‚¤ì›Œë“œ" if lang == 'ko' else "KeyQualities": ["ìë™ì¶”ì¶œ"],
            "ìš”ì•½" if lang == 'ko' else "Summary": response.strip()
        }

def upsert_ideal_to_db(engine, company_name, keywords, summary, language='ko'):
    insert_query = text("""
        INSERT INTO ideal_table (íšŒì‚¬, ì¸ì¬ìƒ_í‚¤ì›Œë“œ, ìš”ì•½, language)
        VALUES (:company, :keyword, :summary, :language)
        ON CONFLICT (íšŒì‚¬, language) DO UPDATE
        SET ì¸ì¬ìƒ_í‚¤ì›Œë“œ = EXCLUDED.ì¸ì¬ìƒ_í‚¤ì›Œë“œ,
            ìš”ì•½ = EXCLUDED.ìš”ì•½
    """)
    with engine.connect() as conn:
        conn.execute(insert_query, {
            'company': company_name,
            'keyword': ",".join(keywords) if isinstance(keywords, list) else str(keywords),
            'summary': summary,
            'language': language
        })
        conn.commit()

# --- Streamlit UI ---

st.title("ì·¨ì—…í•˜ JOB")

option = st.sidebar.radio("ê¸°ëŠ¥ ì„ íƒ", ["ê³µê³  ê²€ìƒ‰", "ìê¸°ì†Œê°œì„œ ì‘ì„±"])

if option == "ê³µê³  ê²€ìƒ‰":

    st.header("ğŸ” ì—­í• ë³„ ë¹ ë¥¸ ì±„ìš© ê²€ìƒ‰")

    user_text = st.text_area("ìŠ¤í™ ì…ë ¥ (ì˜ˆ: 'ì„œìš¸ ê±°ì£¼ ì‹ ì…, 4ë…„ì œ ì¡¸, íŒŒì´ì¬ ê°€ëŠ¥')")

    if st.button("ê²€ìƒ‰ ì‹¤í–‰"):

        async def run_cli_side(text):
            spec = await parse_spec(text)
            applied = await map_filters(spec)
            expanded_roles = applied.get("expanded_roles") or []
            results = {}
            if expanded_roles:
                results = await crawl_by_roles_multi(expanded_roles, per_role=2)
            return applied, results

        applied, grouped = asyncio.run(run_cli_side(user_text))

        st.write("## ê²€ìƒ‰ ê²°ê³¼")

        for role_kw in (applied.get("expanded_roles") or []):

            docs = grouped.get(role_kw, [])

            st.subheader(f"â–¶ {role_kw}")

            if not docs:
                st.write("- (ê²°ê³¼ ì—†ìŒ)")
            else:
                for d in docs:
                    st.markdown(f"**{d.title if d.title else '(ì œëª© ì—†ìŒ)'}**")
                    st.write(f"ğŸ”— [ë§í¬]({d.url})")
                    st.markdown("---")

elif option == "ìê¸°ì†Œê°œì„œ ì‘ì„±":

    st.header("âœï¸ ìê¸°ì†Œê°œì„œ ì‘ì„± & ì²¨ì‚­")

    company = st.text_input("ì§€ì› íšŒì‚¬ëª…")
    job = st.text_input("ì§€ì› ì§ë¬´")
    spec = st.text_area("ë³¸ì¸ ìŠ¤í™ ë° ê²½í—˜ ì…ë ¥")
    language = st.selectbox("ì–¸ì–´ ì„ íƒ", ["ko", "en"])
    char_limit = st.number_input("ìµœëŒ€ ê¸€ì ìˆ˜ (0ì€ ì œí•œ ì—†ìŒ)", min_value=0, step=10, value=0)
    use_example = st.checkbox("ë‚´ë¶€ DB ìì†Œì„œ ì˜ˆì‹œ ì°¸ê³  ì‚¬ìš©")

    if company and job and spec:
        # ì¸ì¬ìƒ ì¡°íšŒ
        keyword, summary = load_ideal_from_db(company, language)
        if keyword and summary:
            company_culture = f"ì¸ì¬ìƒ í‚¤ì›Œë“œ: {keyword}\nìš”ì•½: {summary}"
            st.success(f"ë‚´ë¶€ DB ì¸ì¬ìƒ ì •ë³´ ì¡°íšŒë¨:\n{company_culture}")
        else:
            api_result = company_ideal_talent_api(model, company, lang=language)
            if language == 'ko':
                keywords = api_result.get("ì¸ì¬ìƒ_í‚¤ì›Œë“œ", [])
                summary_text = api_result.get("ìš”ì•½", "")
            else:
                keywords = api_result.get("KeyQualities", [])
                summary_text = api_result.get("Summary", "")
            company_culture = f"ì¸ì¬ìƒ í‚¤ì›Œë“œ: {', '.join(keywords)}\nìš”ì•½: {summary_text}"
            st.info("APIë¡œ ì¸ì¬ìƒ ì •ë³´ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.")
            st.write(company_culture)
            try:
                upsert_ideal_to_db(engine, company, keywords, summary_text, language)
            except Exception as e:
                st.warning(f"DB ì €ì¥ ì˜¤ë¥˜: {e}")

        # ìì†Œì„œ ì˜ˆì‹œ ì¡°íšŒ
        filtered_resume = load_resume_from_db(company, job)

        # ë¬¸í•­ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ ë° ì„ íƒ UI
        if use_example and not filtered_resume.empty:
            q_list = filtered_resume['q'].dropna().unique().tolist()
        else:
            q_list = [
                "ìê¸°ì†Œê°œ (ëŒ€ì¸ê´€ê³„, ì¥ë‹¨ì , ì„±ì¥ê³¼ì • ë“±)",
                "ì§€ì›ë™ê¸° ë° ì…ì‚¬ í›„ í¬ë¶€",
                "ë³¸ì¸ì˜ ê°•ì  ë° ì—­ëŸ‰",
                "ìœ„ê¸°ê·¹ë³µ ì‚¬ë¡€",
                "ì£¼ë„ì ìœ¼ë¡œ ì—…ë¬´ ìˆ˜í–‰í•œ ê²½í—˜"
            ] if language == 'ko' else [
                "Introduction and motivation",
                "Key experience and skills",
                "Fit with company and role",
                "Background and strengths",
                "Goals and aspirations"
            ]

        selected_idx = st.selectbox(
            "ì‘ì„±í•  ìê¸°ì†Œê°œì„œ ë¬¸í•­ì„ ì„ íƒí•˜ì„¸ìš”",
            options=range(1, len(q_list) + 1),
            format_func=lambda x: f"{x}. {q_list[x-1]}"
        )
        selected_question = q_list[selected_idx - 1]
        st.write(f"ì„ íƒí•œ ë¬¸í•­: {selected_question}")

        if st.button("ìê¸°ì†Œê°œì„œ ìƒì„± ë° ì²¨ì‚­"):
            example_resume = None
            if use_example and not filtered_resume.empty and selected_question in filtered_resume['q'].values:
                chosen_row = filtered_resume[filtered_resume['q'] == selected_question].iloc[0]
                example_resume = {
                    "q": selected_question,
                    "a": chosen_row.get('a', ''),
                    "advice": chosen_row.get('advice', ''),
                }
            if example_resume is None:
                example_resume = {"q": selected_question, "a": "", "advice": ""}

            base_prompt, reflection_prompt = get_prompts(language)
            generate_prompt = make_job_prompt(base_prompt, company_culture=company_culture,
                                              example_resume=example_resume, char_limit=char_limit)

            state = {"messages": [HumanMessage(content=f"ì§€ì› íšŒì‚¬: {company}\nì§€ì› ì§ë¬´: {job}\nìŠ¤í™ ë° ê²½í—˜: {spec}")]}

            builder = StateGraph(State)
            builder.add_node("generate", lambda s: generate(s, generate_prompt, char_limit))
            builder.add_node("reflect", lambda s: reflect(s, reflection_prompt))
            builder.add_edge(START, "generate")
            builder.add_edge("reflect", "generate")

            graph = builder.compile()

            stream_outputs = graph.stream(state)

            final_resume = None
            reflection_content = None

            for stream_item in stream_outputs:
                node, val = list(stream_item.items())[0]
                content = val["messages"][-1].content

                if char_limit > 0 and len(content) > char_limit:
                    st.warning(f"âš ï¸ ìƒì„±ëœ ìê¸°ì†Œê°œì„œê°€ {char_limit}ìë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")

                if node == "generate":
                    final_resume = content
                    st.subheader("ìƒì„±ëœ ìê¸°ì†Œê°œì„œ")
                    st.text_area("ìê¸°ì†Œê°œì„œ ë‚´ìš©", pretty_print(final_resume), height=300)
                elif node == "reflect":
                    reflection_content = content
                    st.subheader("ì²¨ì‚­ í”¼ë“œë°±")
                    st.text_area("í”¼ë“œë°± ë‚´ìš©", pretty_print(reflection_content), height=200)

                state["messages"].append(val["messages"][-1])

    else:
        st.info("ì§€ì› íšŒì‚¬ëª…, ì§€ì› ì§ë¬´, ë³¸ì¸ ìŠ¤í™ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
